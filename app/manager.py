import configparser
import datetime
import json
import re
import urllib3

import pandas as pd
import requests

from typing import Any
from pandas import NaT
from sqlalchemy import select

from database.db_manager import get_session
from database.models import Analytics, Specialists
from enums import ANALYTICS, ANALYTICS_TO_BITRIX, SPECIALISTS, BitrixDealsEnum


# –û—Ç–∫–ª—é—á–∞–µ–º –≤—Å–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è urllib3
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)


class SQLManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –ø–æ –∑–∞–≥—Ä—É–∑–∫–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ CSV –≤ PostgreSQL."""

    def __init__(self, logger, messages):
        self.logger = logger
        self.session = get_session()
        self.messages = messages

    def process_analytics(self, df, from_scratch=False):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∞–Ω–∞–ª–∏—Ç–∏–∫. –ì—Ä—É–∑–∏–º –±–µ–∑ –ø—Ä–æ–≤–µ—Ä–∫–∏ —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏, —Ç.–∫. –Ω–µ—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –µ—ë –ø—Ä–æ–≤–µ—Ä–∏—Ç—å."""

        initial_count = df.shape[0]
        self.logger.info(f"[SQLManager] –ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞–Ω–∞–ª–∏—Ç–∏–∫: {initial_count} –∑–∞–ø–∏—Å–µ–π")

        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –ø–∞—Ü–∏–µ–Ω—Ç–æ–≤
        len_df = df.shape[0]
        df = df[df["–ö–∞—Ç–µ–≥–æ—Ä–∏—è –ø–∞—Ü–∏–µ–Ω—Ç–∞"] != "–¢–µ—Å—Ç–æ–≤—ã–π –ø–∞—Ü–∏–µ–Ω—Ç"]
        skipped_rows = len_df - df.shape[0]

        if skipped_rows > 0:
            msg = f"–ü—Ä–æ–ø—É—â–µ–Ω–æ —Ç–µ—Å—Ç–æ–≤—ã—Ö –ø–∞—Ü–∏–µ–Ω—Ç–æ–≤: {skipped_rows}"
            self._add_message(msg)
            self.logger.info(f"[SQLManager] {msg}")

        # –í—ã–±–æ—Ä –∏ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫
        columns_to_keep = [col for col in [col.strip() for col in df.columns] if col in ANALYTICS]
        df.columns = df.columns.str.strip()
        df = df[columns_to_keep]
        df = df.rename(columns=ANALYTICS)
        df = df.where(pd.notna(df), None)

        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Å–ª—É–∂–µ–±–Ω—ã—Ö —É—Å–ª—É–≥
        len_df = df.shape[0]
        df = df[~df['okmu_code'].str.startswith('Q', na=False)]
        skipped_rows = len_df - df.shape[0]

        if skipped_rows > 0:
            msg = f"–ü—Ä–æ–ø—É—â–µ–Ω–æ —Å–ª—É–∂–µ–±–Ω—ã—Ö —É—Å–ª—É–≥: {skipped_rows}"
            self._add_message(msg)
            self.logger.info(f"[SQLManager] {msg}")

        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —Å—Ç–∞—Ç—É—Å—É
        len_df = df.shape[0]
        df = df[df["status"].isin(["–≤—ã–ø–æ–ª–Ω–µ–Ω–æ", "–∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω"])]
        skipped_rows = len_df - df.shape[0]

        if skipped_rows > 0:
            msg = f"–ü—Ä–æ–ø—É—â–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π —Å –Ω–µ–∞–∫—Ç—É–∞–ª—å–Ω—ã–º–∏ —Å—Ç–∞—Ç—É—Å–∞–º–∏: {skipped_rows}"
            self._add_message(msg)
            self.logger.info(f"[SQLManager] {msg}")

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ–ª—è age - –∏–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ —Ü–∏—Ñ—Ä—ã
        if "age" in df.columns:
            df["age"] = df["age"].apply(
                lambda x: int(re.search(r"\d+", str(x)).group())
                if pd.notna(x) and re.search(r"\d+", str(x))
                else None
            )
            self.logger.debug("[SQLManager] –ü–æ–ª–µ 'age' –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ")

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ–ª—è total_amount - –∑–∞–Ω—É–ª—è–µ–º –ø—Ä–æ—á–µ—Ä–∫–∏
        if "total_amount" in df.columns:
            df["total_amount"] = df["total_amount"].apply(
                lambda x: x if x != "-" else None
            )
            self.logger.debug("[SQLManager] –ü–æ–ª–µ 'total_amount' –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ")

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ–ª–µ–π –¥–∞—Ç—ã
        date_columns = ["date", "birth_date"]

        for col in date_columns:
            if col in df.columns:
                df[col] = df[col].apply(self._parse_date)
                self.logger.debug(f"[SQLManager] –ü–æ–ª–µ –¥–∞—Ç—ã '{col}' –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ")

        df = df.replace({pd.NaT: ""})
        df = df.map(lambda x: "" if x is NaT else x)

        final_count = df.shape[0]
        self.logger.info(f"[SQLManager] –ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –æ—Å—Ç–∞–ª–æ—Å—å {final_count} –∑–∞–ø–∏—Å–µ–π –∏–∑ {initial_count}")

        if from_scratch:
            # –£–¥–∞–ª—è–µ–º –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º—ã–µ –∑–∞–ø–∏—Å–∏
            instance_codes = list(df['instance_code'])
            _filter = Analytics.instance_code.in_(instance_codes)
            deleted_count = self.session.query(Analytics).filter(_filter).delete(synchronize_session=False)

            if deleted_count > 0:
                msg = f"–£–¥–∞–ª–µ–Ω–æ —Å—Ç–∞—Ä—ã—Ö –∑–∞–ø–∏—Å–µ–π –∞–Ω–∞–ª–∏—Ç–∏–∫: {deleted_count}"
                self._add_message(msg)
                self.logger.info(f"[SQLManager] {msg}")

        records_to_insert = df.to_dict("records")
        self.messages['statistics']['analytics']['records'] = len(records_to_insert)
        self._bulk_upload(Analytics, records_to_insert, "–∞–Ω–∞–ª–∏—Ç–∏–∫–∞–º")

        return df

    def process_specialists(self, df):
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–æ–≤."""

        initial_count = df.shape[0]
        self.logger.info(f"[SQLManager] –ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–æ–≤: {initial_count} –∑–∞–ø–∏—Å–µ–π")

        columns_to_keep = [col for col in df.columns if col in SPECIALISTS]
        df = df[columns_to_keep]
        df = df.rename(columns=SPECIALISTS)
        self.logger.debug(f"[SQLManager] –í—ã–±—Ä–∞–Ω–æ {len(columns_to_keep)} –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ–ª—è patient_age - –∏–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ —Ü–∏—Ñ—Ä—ã
        if "patient_age" in df.columns:
            df["patient_age"] = df["patient_age"].apply(
                lambda x: int(re.search(r"\d+", str(x)).group())
                if pd.notna(x) and re.search(r"\d+", str(x))
                else None
            )
            self.logger.debug("[SQLManager] –ü–æ–ª–µ 'patient_age' –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ")

        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∑–∞–ø–∏—Å–µ–π
        self.logger.debug("[SQLManager] –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∑–∞–ø–∏—Å–µ–π —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–æ–≤")
        existing_numbers = set(
            number[0] for number in
            self.session.execute(select(Specialists.material_number)).all()
        )
        self.logger.debug(f"[SQLManager] –ù–∞–π–¥–µ–Ω–æ {len(existing_numbers)} —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∑–∞–ø–∏—Å–µ–π")

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ–ª–µ–π –¥–∞—Ç—ã
        date_columns = ["date_d0"]

        for col in date_columns:
            if col in df.columns:
                df[col] = df[col].apply(self._parse_date)
                self.logger.debug(f"[SQLManager] –ü–æ–ª–µ –¥–∞—Ç—ã '{col}' –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ")

        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ –∑–∞–ø–∏—Å–∏
        df = df.dropna(subset=["material_number"])
        new_records = df[~df["material_number"].isin(existing_numbers)]

        if new_records.empty:
            msg = "–ù–µ—Ç –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π –ø–æ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞–º –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏"
            self._add_message(msg)
            self.logger.info(f"[SQLManager] {msg}")
        else:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∑–∞–ø–∏—Å–∏ –≤ —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π
            new_records = new_records.replace({pd.NaT: ""})
            new_records = new_records.map(lambda x: "" if x is NaT else x)
            records_to_insert = new_records.to_dict("records")

            self.messages['statistics']['specialists']['records'] = len(records_to_insert)
            self._bulk_upload(Specialists, records_to_insert, "—Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞–º")

    def _bulk_upload(self, model, records, entity):
        """–ú–∞—Å—Å–æ–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –∑–∞–ø–∏—Å–µ–π –≤ –ë–î."""
        
        try:
            total_rows = len(records)
            chunk_size = 50000
            self.logger.info(f"[SQLManager] –ù–∞—á–∞–ª–æ –º–∞—Å—Å–æ–≤–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ {total_rows} –∑–∞–ø–∏—Å–µ–π –ø–æ {entity} (—á–∞–Ω–∫–∏ –ø–æ {chunk_size})")

            for i in range(0, len(records), chunk_size):
                chunk = records[i:i + chunk_size]

                self.session.bulk_insert_mappings(model, chunk)
                self.session.commit()

                print(f"\r[SQLManager] –ó–∞–≥—Ä—É–∑–∫–∞: {min(i + chunk_size, total_rows)}/{total_rows} –∑–∞–ø–∏—Å–µ–π...", end="", flush=True)

            print()
            msg = f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π –ø–æ {entity}: {total_rows}"
            self._add_message(msg)
            self.logger.info(f"[SQLManager] {msg}")
        except Exception as e:
            self.session.rollback()

            err = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö –ø–æ {entity}: {str(e)}"
            self._add_error(err)
            self.logger.error(f"[SQLManager] {err}", exc_info=True)
            raise

    def _add_message(self, message: str) -> None:
        """–î–æ–±–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –æ—Ç—á—ë—Ç."""
        self.messages['messages'].append(message)

    def _add_error(self, error: str) -> None:
        """–î–æ–±–∞–≤–∏—Ç—å –æ—à–∏–±–∫—É –≤ –æ—Ç—á—ë—Ç."""
        if isinstance(self.messages.get('errors'), list):
            self.messages['errors'].append(error)
        else:
            self.messages['errors'] = [error]

    @staticmethod
    def _parse_date(date_str):
        if date_str is not None:
            return str(date_str)

        else:
            return None


class BitrixManager:
    HEADERS = {"Content-Type": "application/json", "Accept": "application/json"}
    SELECT: list = []
    FILTER: dict[str: Any] = {}
    ORDER = {"DATE_CREATE": "ASC"}

    DATA = {
        "SELECT": SELECT,
        "FILTER": FILTER,
        "ORDER": ORDER,
        "start": 0,
    }

    def __init__(self, logger, messages):
        self.logger = logger
        self.messages = messages
        self.reg_num_field = BitrixDealsEnum.VAR_TO_FIELD[BitrixDealsEnum.REG_NUM]
        self.specialist_execution = BitrixDealsEnum.VAR_TO_FIELD[BitrixDealsEnum.SPECIALIST_EXECUTION]

        self._init_config()

    def process(self, df):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –ø–∞—Ü–∏–µ–Ω—Ç–æ–≤ –≤ Bitrix."""
        
        initial_count = df.shape[0]
        self.logger.info(f"[BitrixManager] –ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–∞—Ü–∏–µ–Ω—Ç–æ–≤: {initial_count} –∑–∞–ø–∏—Å–µ–π")

        columns_to_keep = [col for col in [col.strip() for col in df.columns] if col in BitrixDealsEnum.NAME_TO_FIELD]
        df.columns = df.columns.str.strip()
        df = df[columns_to_keep]
        df = df.rename(columns=BitrixDealsEnum.NAME_TO_FIELD)
        df = df.where(pd.notna(df), None)
        self.logger.debug(f"[BitrixManager] –í—ã–±—Ä–∞–Ω–æ {len(columns_to_keep)} –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")

        for col in df.select_dtypes(include=["datetime64"]).columns:
            df[col] = df[col].astype(str)
            self.logger.debug(f"[BitrixManager] –ü–æ–ª–µ –¥–∞—Ç—ã '{col}' –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–æ –≤ —Å—Ç—Ä–æ–∫—É")

        records = df.to_dict("records")

        reg_nums = [rec[self.reg_num_field] for rec in records]
        reg_nums = [reg_num for reg_num in reg_nums if reg_num]
        self.logger.debug(f"[BitrixManager] –ù–∞–π–¥–µ–Ω–æ {len(reg_nums)} —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö –Ω–æ–º–µ—Ä–æ–≤")
        
        uploaded_by_reg_num = self._get_records_by_reg_nums(reg_nums)

        records_to_upload = [rec for rec in records if rec[self.reg_num_field] not in uploaded_by_reg_num]
        skipped_count = len(records) - len(records_to_upload)

        if skipped_count > 0:
            msg = f"–ü—Ä–æ–ø—É—â–µ–Ω–æ —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –ø–∞—Ü–∏–µ–Ω—Ç–æ–≤: {skipped_count}"
            self._add_message(msg)
            self.logger.info(f"[BitrixManager] {msg}")

        for record in records_to_upload:
            record["PATIENTS_CATEGORY_ID"] = self.PATIENTS_CATEGORY_ID
            record[BitrixDealsEnum.CREATION] = record[BitrixDealsEnum.CREATION]
            record[BitrixDealsEnum.VAR_TO_FIELD[BitrixDealsEnum.BIRTHDAY]] = record[BitrixDealsEnum.VAR_TO_FIELD[BitrixDealsEnum.BIRTHDAY]]

        amount = len(records_to_upload)

        if amount > 0:
            self.logger.info(f"[BitrixManager] –ù–∞—á–∞–ª–æ –∑–∞–≥—Ä—É–∑–∫–∏ {amount} –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π –≤ Bitrix")

            for num, record in enumerate(records_to_upload, 1):
                self._upload_to_bitrix(record, self.WEBHOOK_URL_PROD)
                print(f"\r[BitrixManager] –í—ã–≥—Ä—É–∑–∫–∞ –≤ Bitrix: {num}/{amount}", end="", flush=True)

            print()
            msg = f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π –ø–æ –ø–∞—Ü–∏–µ–Ω—Ç–∞–º: {amount}"
            self._add_message(msg)
            self.messages['statistics']['users']['records'] = amount
            self.logger.info(f"[BitrixManager] {msg}")
        else:
            msg = "–ù–µ—Ç –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π –ø–æ –ø–∞—Ü–∏–µ–Ω—Ç–∞–º –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏"
            self._add_message(msg)
            self.logger.info(f"[BitrixManager] {msg}")

    def _add_message(self, message: str) -> None:
        """–î–æ–±–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –æ—Ç—á—ë—Ç."""
        self.messages['messages'].append(message)

    def _add_error(self, error: str) -> None:
        """–î–æ–±–∞–≤–∏—Ç—å –æ—à–∏–±–∫—É –≤ –æ—Ç—á—ë—Ç."""
        if isinstance(self.messages.get('errors'), list):
            self.messages['errors'].append(error)
        else:
            self.messages['errors'] = [error]

    def process_analytics(self, df):
        df = (
            df
            [df["admission_type"] == "–ö–û–°–ú–ï–¢–û–õ–û–ì–ò–Ø"]
            [df["department_execution"] == "–•–ì–ú –ö–û–°–ú –ê–ú–ë"]
            [ANALYTICS_TO_BITRIX.values()]
        )
        df["total_amount"] = df["total_amount"].astype(float)
        df = df.groupby(
            [
                'registration_number',
                'full_name',
                'appointment_date',
                'department_execution',
                'specialist_execution',
            ],
            as_index=False,
        )["total_amount"].sum() #todo

        records = df.to_dict('records')

        for record in records:
            # –ù–∞—Ö–æ–¥–∏–º –∫–æ–Ω—Ç–∞–∫—Ç —é–∑–µ—Ä–∞ –ø–æ –µ–≥–æ —Ä–µ–≥. –Ω–æ–º–µ—Ä—É.
            contact = self._get_contact_by_reg_number(record['registration_number'])

            if contact:
                ad = record['appointment_date']

                if ad:
                    ad = datetime.datetime.strptime(ad, '%d.%m.%Y')
                    ad = datetime.datetime.strftime(ad, '%d.%m.%Y %H:%M:%S')

                # –°–æ–∑–¥–∞–µ–º —Å–¥–µ–ª–∫—É
                deal = requests.post(
                    url='https://crm.grandmed.ru/rest/27036/pnkrzq23s3h1r71c/crm.deal.add',
                    headers={'Content-Type': 'application/json', 'Accept': 'application/json'},
                    data=json.dumps({
                        'fields': {
                            'CATEGORY_ID': '71',
                            'UF_CRM_673DEA05D361C': ad,
                            'UF_CRM_1641810471884': record['specialist_execution'],
                            'STAGE_ID': 'C71:WON',
                            'ASSIGNED_BY_ID': '19240',
                            'TYPE_ID': 'UC_GTR0J0',
                            'OPPORTUNITY': record['total_amount'],
                        },
                    }),
                    verify=False,
                ).json()

                # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–∞–∫—Ç –≤ —Å–¥–µ–ª–∫—É
                requests.post(
                    url='https://crm.grandmed.ru/rest/27036/pnkrzq23s3h1r71c/crm.deal.contact.add',
                    headers={'Content-Type': 'application/json', 'Accept': 'application/json'},
                    data=json.dumps({
                        'id': deal['result'],
                        'fields': {'CONTACT_ID': contact},
                    }),
                    verify=False,
                ).json()

            else:
                print(record['registration_number'])

    def _get_contact_by_reg_number(self, reg_num):
        """–ó–¥–µ—Å—å –≤—Å–µ –æ—á–µ–Ω—å –ø–ª–æ—Ö–æ. –£—Å—Ç–∞–ª —É–∂–µ –≤—Å–µ –≤—ã–Ω–æ—Å–∏—Ç—å –ø–æ —ç–Ω–∞–º–∞–º –∏ –ø—Ä–æ—á.
        –í –∏–¥–µ–∞–ª–µ, –Ω–∞ —ç—Ç–æ–º —ç—Ç–∞–ø–µ —É–∂–µ –Ω–∞–¥–æ –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø—Ä–æ–µ–∫—Ç–∞ –ø–µ—Ä–µ–ø–∏—Å–∞—Ç—å."""

        response = requests.post(
            url='https://crm.grandmed.ru/rest/27036/pnkrzq23s3h1r71c/crm.contact.list',
            headers={'Content-Type': 'application/json', 'Accept': 'application/json'},
            data=json.dumps({
                'SELECT': ['ID'],
                'FILTER': {
                    'UF_CRM_1744899027': reg_num,
                },
                'ORDER': {'DATE_CREATE': 'ASC'},
                'start': 0,
            }),
            verify=False,
        ).json()

        if 'result' in response and response['result']:
            return response['result'][0]['ID']

        else:
            return None

    def _get_records_by_reg_nums(self, reg_nums):
        """–ü–æ–ª—É—á–∞–µ–º —Ä–µ–≥. –Ω–æ–º–µ—Ä–∞ –∏–∑ –±–∏—Ç—Ä–∏–∫—Å–∞ —á—Ç–æ–±—ã –ø–æ–Ω—è—Ç—å, —á—Ç–æ —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ."""

        self.logger.debug(f"[BitrixManager] –ó–∞–ø—Ä–æ—Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∑–∞–ø–∏—Å–µ–π –¥–ª—è {len(reg_nums)} —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö –Ω–æ–º–µ—Ä–æ–≤")

        _filter = {
            f"@{self.reg_num_field}": reg_nums,
            "CATEGORY_ID": self.PATIENTS_CATEGORY_ID,
        }
        _select = ['*']

        self.DATA.update({
            "FILTER": _filter,
            "SELECT": _select,
        })

        records_by_reg_nums = self._get_response(self.LIST_METHOD, self.WEBHOOK_URL_PROD)
        reg_nums = set([rec[self.reg_num_field] for rec in records_by_reg_nums])

        self.logger.info(f"[BitrixManager] –ù–∞–π–¥–µ–Ω–æ —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö –Ω–æ–º–µ—Ä–æ–≤: {len(reg_nums)}")

        return reg_nums

    def _get_response(self, method, url):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –æ—Ç Bitrix API —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π."""
        
        result = []

        def get_records():
            response = requests.post(
                f"{url}{method}",
                headers=self.HEADERS,
                data=json.dumps(self.DATA),
                verify=False,
            )

            response.raise_for_status()
            recs = response.json()

            return recs

        try:
            _next = 0
            page_count = 0

            while _next is not None:
                self.DATA["start"] = _next
                records = get_records()
                result.extend(records["result"])
                page_count += 1

                _next = records.get("next")
                self.logger.debug(f"[BitrixManager] –ü–æ–ª—É—á–µ–Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_count}, –∑–∞–ø–∏—Å–µ–π: {len(records['result'])}, next: {_next}")

            self.logger.debug(f"[BitrixManager] –í—Å–µ–≥–æ –ø–æ–ª—É—á–µ–Ω–æ {len(result)} –∑–∞–ø–∏—Å–µ–π –∑–∞ {page_count} —Å—Ç—Ä–∞–Ω–∏—Ü")

        except requests.exceptions.RequestException as e:
            error_msg = f"–û—à–∏–±–∫–∞ HTTP-–∑–∞–ø—Ä–æ—Å–∞ –∫ Bitrix API: {str(e)}"
            self.logger.error(f"[BitrixManager] {error_msg}")
            self._add_error(error_msg)
            raise
        except json.JSONDecodeError as e:
            error_msg = "–û—à–∏–±–∫–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞ —Å–µ—Ä–≤–µ—Ä–∞"
            self.logger.error(f"[BitrixManager] {error_msg}: {str(e)}")
            self._add_error(error_msg)
            raise
        except Exception as e:
            error_msg = f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ Bitrix API: {str(e)}"
            self.logger.error(f"[BitrixManager] {error_msg}", exc_info=True)
            self._add_error(error_msg)
            raise

        return result

    def _upload_to_bitrix(self, record, url):
        """–í—ã–≥—Ä—É–∑–∫–∞ —Å–¥–µ–ª–∫–∏ –≤ Bitrix."""

        deal_id = None

        try:
            response = requests.post(f"{url}{self.ADD_METHOD}", json={"fields": record}, verify=False)
            response.raise_for_status()

            if response.status_code == 200:
                result = response.json()

                if "error" in result:
                    error_msg = f"–û—à–∏–±–∫–∞ Bitrix –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —Å–¥–µ–ª–∫–∏: {result.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}"
                    self.logger.warning(f"[BitrixManager] {error_msg}")
                    # –ù–µ –¥–æ–±–∞–≤–ª—è–µ–º –≤ –æ–±—â–∏–π —Å–ø–∏—Å–æ–∫ –æ—à–∏–±–æ–∫, —Ç.–∫. —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –º–∞—Å—Å–æ–≤–∞—è –æ–ø–µ—Ä–∞—Ü–∏—è
                else:
                    deal_id = result['result']
            else:
                error_msg = f"–û—à–∏–±–∫–∞ HTTP –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {response.status_code}"
                self.logger.error(f"[BitrixManager] {error_msg}: {response.text}")

        except requests.exceptions.RequestException as e:
            self.logger.error(f"[BitrixManager] –û—à–∏–±–∫–∞ HTTP-–∑–∞–ø—Ä–æ—Å–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –≤ Bitrix: {str(e)}")
        except json.JSONDecodeError as e:
            self.logger.error(f"[BitrixManager] –û—à–∏–±–∫–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞ —Å–µ—Ä–≤–µ—Ä–∞: {str(e)}")
        except Exception as e:
            self.logger.error(f"[BitrixManager] –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –≤ Bitrix: {str(e)}", exc_info=True)

        return deal_id

    def _init_config(self):
        conf_path = "app/bitrix.conf"
        config = configparser.ConfigParser()
        config.read(conf_path)

        self.WEBHOOK_URL_PROD = config.get("base", "webhook_url_prod")
        self.WEBHOOK_URL_TEST = config.get("base", "webhook_url_test")
        self.PATIENTS_CATEGORY_ID = config.get("deals", "patients_category_id")
        self.ANALYTICS_CATEGORY_ID = config.get("deals", "analytics_category_id")
        self.GET_METHOD = config.get("deals", "get_method")
        self.ADD_METHOD = config.get("deals", "add_method")
        self.LIST_METHOD = config.get("deals", "list_method")
        self.PRODUCT_ID_PROD = config.get("deals", "product_id_prod")
        self.PRODUCT_ID_TEST = config.get("deals", "product_id_test")


class TelegramManager:
    def __init__(self, logger):
        self.logger = logger
        self.token = None
        self.user_id = None
        self._init_config()

    def _init_config(self):
        try:
            conf_path = "app/tg.conf"
            config = configparser.ConfigParser()

            if not config.read(conf_path, encoding="utf-8"):
                self.logger.warning(f"[TelegramManager] –§–∞–π–ª –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {conf_path}")
                return

            self.token = config.get("telegram", "token", fallback=None)
            self.user_id = config.get("telegram", "user_id", fallback=None)

            if not self.token or not self.user_id:
                self.logger.warning("[TelegramManager] –í tg.conf –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç token –∏–ª–∏ user_id –≤ —Å–µ–∫—Ü–∏–∏ [telegram]")

        except Exception as e:
            self.logger.error(f"[TelegramManager] –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")

    def send_messages(self, messages, errors=None, statistics=None) -> bool:
        """–û—Ç–ø—Ä–∞–≤–∫–∞ –æ—Ç—á—ë—Ç–∞ –≤ Telegram."""
        
        try:
            errors = errors or []
            statistics = statistics or {}
            
            if not messages and not errors:
                self.logger.info("[TelegramManager] –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏")
                return False

            if not self.token or not self.user_id:
                self.logger.warning("[TelegramManager] –ù–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω token –∏–ª–∏ user_id")
                return False

            # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è
            parts = []
            
            # –ó–∞–≥–æ–ª–æ–≤–æ–∫
            parts.append("üìä *–û—Ç—á—ë—Ç –æ –≤—ã–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö*")
            parts.append("")
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            if statistics:
                stats_parts = []
                for key, value in statistics.items():
                    if isinstance(value, dict):
                        uploaded = "‚úì" if value.get('uploaded') else "‚úó"
                        processed = "‚úì" if value.get('processed') else "‚úó"
                        records = value.get('records', 0)
                        
                        name_map = {
                            'analytics': '–ê–Ω–∞–ª–∏—Ç–∏–∫–∏',
                            'specialists': '–°–ø–µ—Ü–∏–∞–ª–∏—Å—Ç—ã',
                            'users': '–ü–∞—Ü–∏–µ–Ω—Ç—ã'
                        }
                        name = name_map.get(key, key)
                        
                        stats_parts.append(
                            f"  {name}:\n"
                            f"    –ó–∞–≥—Ä—É–∑–∫–∞: {uploaded} | –û–±—Ä–∞–±–æ—Ç–∫–∞: {processed}\n"
                            f"    –ó–∞–ø–∏—Å–µ–π: {records}"
                        )
                
                if stats_parts:
                    parts.append("*–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:*")
                    parts.extend(stats_parts)
                    parts.append("")
            
            # –°–æ–æ–±—â–µ–Ω–∏—è
            if messages:
                parts.append("*–î–µ—Ç–∞–ª–∏:*")
                for msg in messages:
                    parts.append(f"  ‚Ä¢ {msg}")
                parts.append("")
            
            # –û—à–∏–±–∫–∏
            if errors:
                error_list = errors if isinstance(errors, list) else [errors]
                parts.append("‚ö†Ô∏è *–û—à–∏–±–∫–∏:*")
                for error in error_list:
                    parts.append(f"  ‚Ä¢ {error}")
                parts.append("")
            
            text = "\n".join(parts)
            
            # –û—Ç–ø—Ä–∞–≤–∫–∞
            url = f"https://api.telegram.org/bot{self.token}/sendMessage"
            payload = {
                "chat_id": str(self.user_id),
                "text": text,
                "parse_mode": "Markdown",
                "disable_web_page_preview": True,
            }

            resp = requests.post(url, json=payload, timeout=15)

            if resp.status_code == 200 and resp.json().get("ok"):
                self.logger.info("[TelegramManager] –°–æ–æ–±—â–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –≤ Telegram")
                return True

            error_msg = f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ Telegram: {resp.status_code} {resp.text}"
            self.logger.error(f"[TelegramManager] {error_msg}")
            return False

        except Exception as e:
            self.logger.error(f"[TelegramManager] –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —Å–æ–æ–±—â–µ–Ω–∏—è: {str(e)}", exc_info=True)
            return False